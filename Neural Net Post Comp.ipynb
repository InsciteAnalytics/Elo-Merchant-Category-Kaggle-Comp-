{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Importing Libs & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T03:11:49.918184Z",
     "start_time": "2019-03-17T03:11:49.898876Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GaussianNoise\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.regularizers import l1\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import BatchNormalization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from plotnine import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T18:06:53.046007Z",
     "start_time": "2019-03-16T18:06:52.895707Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "XtrainLR = pd.read_pickle('XtrainLR');Ytrain = pd.read_pickle('Ytrain');XtestLR = pd.read_pickle('XtestLR')\n",
    "XvalLR = pd.read_pickle('XvalLR');Yval = pd.read_pickle('Yval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T02:35:30.271650Z",
     "start_time": "2019-03-17T02:35:29.513353Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "XtrainRF = pd.read_pickle('XtrainRF'); XtestRF = pd.read_pickle('XtestRF'); XvalRF = pd.read_pickle('XvalLR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Scaling numerical features of all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T20:28:17.610200Z",
     "start_time": "2019-03-16T20:28:16.473020Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "XtrainLR[['purchase_amount', 'Cat_1_Y',\\\n",
    "       'Cat2Tot1', 'Cat2Tot2', 'Cat2Tot3', 'Cat2Tot4', 'Cat3TotA', 'Cat3TotB',\\\n",
    "       'AvgPurAmt', 'TimeSpent', 'CLV', 'numerical_2', 'avg_sales_lag3',\\\n",
    "       'avg_purchases_lag3', 'avg_purchases_lag6', 'active_months_lag6',\\\n",
    "       'avg_sales_lag12']]=preprocessing.scale(np.asarray(XtrainLR[['purchase_amount', 'Cat_1_Y',\\\n",
    "       'Cat2Tot1', 'Cat2Tot2', 'Cat2Tot3', 'Cat2Tot4', 'Cat3TotA', 'Cat3TotB',\\\n",
    "       'AvgPurAmt', 'TimeSpent', 'CLV', 'numerical_2', 'avg_sales_lag3',\\\n",
    "       'avg_purchases_lag3', 'avg_purchases_lag6', 'active_months_lag6',\\\n",
    "       'avg_sales_lag12']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T20:28:17.872318Z",
     "start_time": "2019-03-16T20:28:17.614870Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "XvalLR[['purchase_amount', 'Cat_1_Y',\\\n",
    "       'Cat2Tot1', 'Cat2Tot2', 'Cat2Tot3', 'Cat2Tot4', 'Cat3TotA', 'Cat3TotB',\\\n",
    "       'AvgPurAmt', 'TimeSpent', 'CLV', 'numerical_2', 'avg_sales_lag3',\\\n",
    "       'avg_purchases_lag3', 'avg_purchases_lag6', 'active_months_lag6',\\\n",
    "       'avg_sales_lag12']]=preprocessing.scale(np.asarray(XvalLR[['purchase_amount', 'Cat_1_Y',\\\n",
    "       'Cat2Tot1', 'Cat2Tot2', 'Cat2Tot3', 'Cat2Tot4', 'Cat3TotA', 'Cat3TotB',\\\n",
    "       'AvgPurAmt', 'TimeSpent', 'CLV', 'numerical_2', 'avg_sales_lag3',\\\n",
    "       'avg_purchases_lag3', 'avg_purchases_lag6', 'active_months_lag6',\\\n",
    "       'avg_sales_lag12']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T17:47:51.341768Z",
     "start_time": "2019-03-16T17:47:50.898Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "XtestLR[['purchase_amount', 'Cat_1_Y',\\\n",
    "       'Cat2Tot1', 'Cat2Tot2', 'Cat2Tot3', 'Cat2Tot4', 'Cat3TotA', 'Cat3TotB',\\\n",
    "       'AvgPurAmt', 'TimeSpent', 'CLV', 'numerical_2', 'avg_sales_lag3',\\\n",
    "       'avg_purchases_lag3', 'avg_purchases_lag6', 'active_months_lag6',\\\n",
    "       'avg_sales_lag12']]=preprocessing.scale(np.asarray(XtestLR[['purchase_amount', 'Cat_1_Y',\\\n",
    "       'Cat2Tot1', 'Cat2Tot2', 'Cat2Tot3', 'Cat2Tot4', 'Cat3TotA', 'Cat3TotB',\\\n",
    "       'AvgPurAmt', 'TimeSpent', 'CLV', 'numerical_2', 'avg_sales_lag3',\\\n",
    "       'avg_purchases_lag3', 'avg_purchases_lag6', 'active_months_lag6',\\\n",
    "       'avg_sales_lag12']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Using Grid Search to check for best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T20:28:39.758008Z",
     "start_time": "2019-03-16T20:28:39.747180Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fix random seed for reproducibility\n",
    "seed = np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T17:31:56.986065Z",
     "start_time": "2019-03-12T17:31:56.964818Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1000, input_dim=24, activation='relu'))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=10000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T17:59:59.607607Z",
     "start_time": "2019-03-12T17:31:58.330601Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=3, random_state=seed)\n",
    "results = cross_val_score(estimator, Xtrain, Ytrain, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Fitting best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T20:29:56.850237Z",
     "start_time": "2019-03-16T20:29:56.845848Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T23:34:42.535642Z",
     "start_time": "2019-03-16T23:34:42.520019Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reduceLR = ReduceLROnPlateau(monitor='loss',factor=0.1,verbose=1,patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T01:43:39.849034Z",
     "start_time": "2019-03-17T01:02:46.198573Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=24, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(400, activation='relu',kernel_regularizer=l2(0.005)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(75, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "# 2. compile the network\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# 3. fit the network\n",
    "history = model.fit(XtrainLR, Ytrain, epochs=250, batch_size=30000, callbacks=[reduceLR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T01:51:57.059812Z",
     "start_time": "2019-03-17T01:51:32.831068Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159684/159684 [==============================] - 19s 122us/step\n",
      "39921/39921 [==============================] - 5s 116us/step\n",
      "Training RMSE: 1.6822908992183263\n",
      "Validation RMSE: 1.687576354278096\n"
     ]
    }
   ],
   "source": [
    "# 4. evaluate the network\n",
    "losstrain = model.evaluate(XtrainLR,Ytrain)\n",
    "lossval = model.evaluate(XvalLR, Yval)\n",
    "print('Training RMSE:',sqrt(losstrain))\n",
    "print('Validation RMSE:',sqrt(lossval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T00:06:45.334110Z",
     "start_time": "2019-03-17T00:06:45.324018Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_92 (Dense)             (None, 500)               12500     \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 400)               200400    \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 300)               120300    \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 150)               30150     \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 75)                7575      \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 50)                3800      \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 451,586\n",
      "Trainable params: 451,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T03:27:33.145970Z",
     "start_time": "2019-03-13T03:27:26.350698Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 5. make predictions\n",
    "Ypred = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T03:27:33.630235Z",
     "start_time": "2019-03-13T03:27:33.145970Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets = pd.DataFrame(Ypred,columns=['target']); targets.to_csv('targets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T18:54:53.256142Z",
     "start_time": "2019-03-11T18:54:48.015129Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123623, 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions = [float(round(x)) for x in probabilities]\n",
    "# accuracy = numpy.mean(predictions == Y)\n",
    "# print(\"Prediction Accuracy: %.2f%%\" % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Making feature dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This was an experiment done using just the 3 features present in the original training set. I ran a Neural Net on just those features to check if predictability was better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:37:23.916232Z",
     "start_time": "2019-03-13T15:37:23.853864Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Xtrain2 = Xtrain[['feature_1_2', 'feature_1_3', 'feature_1_4', 'feature_1_5','feature_2_2', 'feature_2_3', 'feature_3_1']]\n",
    "Xtest2 = Xtest[['feature_1_2', 'feature_1_3', 'feature_1_4', 'feature_1_5','feature_2_2', 'feature_2_3', 'feature_3_1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### NN on features only dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:22:16.409351Z",
     "start_time": "2019-03-13T16:22:16.393698Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(150, input_dim=7, activation='relu'))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "# 2. compile the network\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics = ['accuracy'])\n",
    "# 3. fit the network\n",
    "history = model.fit(Xtrain2, Ytrain, epochs=50, batch_size=15000)\n",
    "# 4. evaluate the network\n",
    "loss, accuracy = model.evaluate(Xtrain2, Ytrain)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Applying Random Forest on features only dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Importing fresh data, fixing issues again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T02:59:48.217691Z",
     "start_time": "2019-03-17T02:59:48.036106Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Train = pd.read_pickle('NewTrain2') \n",
    "\n",
    "Train = Train[['first_active_month','feature_1','feature_2','feature_3','target']]\n",
    "\n",
    "Xtrain = Train.loc[:,Train.columns!='target']; Ytrain = Train.loc[:,'target']\n",
    "\n",
    "Xtrain.first_active_month = Xtrain.first_active_month.astype('category')\n",
    "\n",
    "Xtrain,Xval,Ytrain,Yval=train_test_split(Xtrain,Ytrain,test_size=0.2)\n",
    "\n",
    "Xtrain.first_active_month = Xtrain.first_active_month.cat.codes\n",
    "\n",
    "Xtrain.drop(['first_active_month'],axis=1,inplace=True); Xval.drop(['first_active_month'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Running RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T04:11:55.110450Z",
     "start_time": "2019-03-17T04:11:44.652840Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "RF = RandomForestRegressor(n_estimators=500, n_jobs=-1, min_samples_leaf=3, max_features=0.5)\n",
    "model = RF.fit(Xtrain, Ytrain)\n",
    "\n",
    "Ypred = RF.predict(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T04:11:55.910577Z",
     "start_time": "2019-03-17T04:11:55.878718Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.686474445851263"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE 1st Check\n",
    "MSE=mean_squared_error(Yval,Ypred)\n",
    "RMSE=sqrt(MSE);RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T04:12:28.492790Z",
     "start_time": "2019-03-17T04:12:28.383546Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Test = pd.read_pickle('NewTest2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T03:57:56.796128Z",
     "start_time": "2019-03-17T03:57:56.328688Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_2    0.474581\n",
       "feature_1    0.449307\n",
       "feature_3    0.076112\n",
       "dtype: float64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FI = pd.Series(RF.feature_importances_,index=Xtrain.columns).sort_values(ascending=False);FI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
